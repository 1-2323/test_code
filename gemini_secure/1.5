import ipaddress
import socket
from urllib.parse import urlparse
from fastapi import FastAPI, HTTPException, Body
import httpx
from bs4 import BeautifulSoup

app = FastAPI()

# Список запрещенных диапазонов (локальные сети и метаданные облаков)
FORBIDDEN_NETWORKS = [
    ipaddress.ip_network("127.0.0.0/8"),    # Loopback
    ipaddress.ip_network("10.0.0.0/8"),     # Private IP
    ipaddress.ip_network("172.16.0.0/12"),  # Private IP
    ipaddress.ip_network("192.168.0.0/16"), # Private IP
    ipaddress.ip_network("169.254.169.254/32"), # AWS/GCP/Azure Metadata
    ipaddress.ip_network("::1/128"),        # IPv6 Loopback
]

def is_safe_url(url: str) -> bool:
    try:
        parsed = urlparse(url)
        if parsed.scheme not in ["http", "https"]:
            return False
        
        # 1. Получаем IP-адрес хоста
        hostname = parsed.hostname
        ip_address = ipaddress.ip_address(socket.gethostbyname(hostname))
        
        # 2. Проверяем, не входит ли IP в запрещенные подсети
        for network in FORBIDDEN_NETWORKS:
            if ip_address in network:
                return False
        return True
    except Exception:
        return False

@app.post("/preview")
async def get_preview(url: str = Body(..., embed=True)):
    # Защита: Валидация URL перед запросом
    if not is_safe_url(url):
        raise HTTPException(status_code=400, detail="Invalid or forbidden URL")

    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            # Защита: Отключаем редиректы или проверяем каждый шаг (follow_redirects=False)
            response = await client.get(url, follow_redirects=False)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, "html.parser")
            
            # Извлекаем описание (из meta или первого абзаца)
            description = ""
            meta_desc = soup.find("meta", attrs={"name": "description"})
            if meta_desc:
                description = meta_desc.get("content", "")
            else:
                p_tag = soup.find("p")
                description = p_tag.text[:150] if p_tag else "No description available"

            return {
                "url": url,
                "title": soup.title.string if soup.title else "No title",
                "description": description.strip()
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error fetching preview: {str(e)}")
