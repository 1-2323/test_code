import os
import stat
import time
import gzip
import shutil
import hashlib
from pathlib import Path
from typing import Optional


class SecureLogRotator:
    """
    Log rotation + archiving with integrity protection.
    - Time-based rotation
    - Gzip archiving
    - SHA-256 integrity hash per archive
    - Read-only permissions after rotation
    """

    def __init__(
        self,
        log_path: Path,
        archive_dir: Path,
        rotate_interval_seconds: int = 86400,
        max_archives: int = 30,
    ):
        self.log_path = log_path
        self.archive_dir = archive_dir
        self.rotate_interval = rotate_interval_seconds
        self.max_archives = max_archives
        self.archive_dir.mkdir(parents=True, exist_ok=True)

    def run(self) -> None:
        if not self.log_path.exists():
            return

        last_modified = self.log_path.stat().st_mtime
        if time.time() - last_modified < self.rotate_interval:
            return

        archive_path = self._rotate()
        self._protect_file(archive_path)
        self._write_hash(archive_path)
        self._cleanup_old_archives()

    def _rotate(self) -> Path:
        timestamp = time.strftime("%Y%m%d%H%M%S")
        archive_name = f"{self.log_path.name}.{timestamp}.gz"
        archive_path = self.archive_dir / archive_name

        with self.log_path.open("rb") as src, gzip.open(archive_path, "wb") as dst:
            shutil.copyfileobj(src, dst)

        self.log_path.unlink()
        self.log_path.touch(mode=0o600)

        return archive_path

    def _protect_file(self, path: Path) -> None:
        path.chmod(stat.S_IRUSR | stat.S_IRGRP)  # read-only

    def _write_hash(self, path: Path) -> None:
        h = hashlib.sha256()
        with path.open("rb") as f:
            for chunk in iter(lambda: f.read(8192), b""):
                h.update(chunk)

        hash_path = path.with_suffix(path.suffix + ".sha256")
        hash_path.write_text(f"{h.hexdigest()}  {path.name}\n")
        hash_path.chmod(stat.S_IRUSR | stat.S_IRGRP)

    def _cleanup_old_archives(self) -> None:
        archives = sorted(
            self.archive_dir.glob(f"{self.log_path.name}.*.gz"),
            key=lambda p: p.stat().st_mtime,
            reverse=True,
        )

        for old in archives[self.max_archives :]:
            hash_file = old.with_suffix(old.suffix + ".sha256")
            old.unlink(missing_ok=True)
            hash_file.unlink(missing_ok=True)
